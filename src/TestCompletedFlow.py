"""
test_complete_flow.py
ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸: ë¶„ë¥˜ â†’ ê²€ìƒ‰ â†’ GPT ë‹µë³€
"""

import os
from dotenv import load_dotenv
from s4_EmbeddingManager import EmbeddingManager
from s5_LegalSearchEngine import LegalSearchEngine
from s61_QueryClassifier import QueryClassifier
from s62_GPTLegalSearchSystem import EnhancedLegalQASystem
import json


def print_section(title: str):
    print("\n" + "="*80)
    print(f"  {title}")
    print("="*80 + "\n")


def test_classification(classifier: QueryClassifier):
    """1ë‹¨ê³„: ì§ˆë¬¸ ë¶„ë¥˜"""
    print_section("1ï¸âƒ£ ì§ˆë¬¸ ë¶„ë¥˜ í…ŒìŠ¤íŠ¸")
    
    queries = [
        "ì œ36ì¡°ê°€ ë­ì•¼?",
        "ë¹„ê³„ ì•ˆì „ ê¸°ì¤€ì€?",
        "ìš°ë¦¬ í˜„ì¥ 3m ë¹„ê³„ ê´œì°®ë‚˜?",
        "ìš©ë„ë³€ê²½ ì ˆì°¨ ì•Œë ¤ì¤˜",
        "ë¹„ê³„ ì ê²€ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ì–´ì¤˜",
        "ì‚°ì—…ì•ˆì „ë³´ê±´ë²•ê³¼ ê±´ì¶•ë²• ì°¨ì´ëŠ”?"
    ]
    
    for query in queries:
        print(f"ğŸ” ì§ˆë¬¸: '{query}'")
        result = classifier.classify(query)
        
        print(f"   ìœ í˜•: {result['query_type']}")
        print(f"   í™•ì‹ ë„: {result['confidence']:.0%}")
        print(f"   í‚¤ì›Œë“œ: {result['key_entities']}")
        
        strategy = classifier.get_search_strategy(result['query_type'])
        print(f"   ê²€ìƒ‰: {strategy['search_method']} (top_k={strategy['top_k']})\n")


def test_search(engine: LegalSearchEngine, classifier: QueryClassifier):
    """2ë‹¨ê³„: ê²€ìƒ‰"""
    print_section("2ï¸âƒ£ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    
    query = "ë¹„ê³„ ì•ˆì „ ê¸°ì¤€ì€?"
    
    classification = classifier.classify(query)
    strategy = classifier.get_search_strategy(classification['query_type'])
    
    print(f"ì§ˆë¬¸: {query}")
    print(f"ìœ í˜•: {classification['query_type']}")
    print(f"ê²€ìƒ‰: {strategy['search_method']}\n")
    
    if strategy['search_method'] == 'hybrid':
        results = engine.hybrid_search(query, top_k=strategy['top_k'])
    elif strategy['search_method'] == 'vector':
        results = engine.vector_search(query, top_k=strategy['top_k'])
    
    print(f"ê²°ê³¼: {len(results)}ê±´\n")
    for i, r in enumerate(results[:3], 1):
        print(f"[{i}] {r['metadata']['doc_name']} (p.{r['metadata']['page']})")
        print(f"    {r['content'][:150]}...\n")


def test_full_qa(qa_system: EnhancedLegalQASystem):
    """3ë‹¨ê³„: ì „ì²´ QA"""
    print_section("3ï¸âƒ£ ì „ì²´ QA ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    
    test_cases = [
        ("ì œ36ì¡°ê°€ ë­ì•¼?", "ë²•ì¡°ë¬¸_ì¡°íšŒ"),
        ("ë¹„ê³„ ì•ˆì „ ê¸°ì¤€ì€?", "ì¼ë°˜_ì •ë³´_ê²€ìƒ‰"),
        ("ìš°ë¦¬ í˜„ì¥ 3m ë¹„ê³„ ê´œì°®ë‚˜?", "ìƒí™©ë³„_ì»¨ì„¤íŒ…")
    ]
    
    for query, expected_type in test_cases:
        print(f"\n{'â”€'*80}")
        print(f"ì§ˆë¬¸: {query}")
        print(f"ì˜ˆìƒ ìœ í˜•: {expected_type}")
        print(f"{'â”€'*80}\n")
        
        # format_for_user=Trueë¡œ í˜¸ì¶œ
        answer = qa_system.generate_answer(query, verbose=True, format_for_user=True)
        
        meta = answer.get("_meta", {})
        actual_type = meta.get("query_type", "")
        
        print(f"\nì‹¤ì œ ìœ í˜•: {actual_type}")
        print(f"ì¼ì¹˜: {'âœ…' if actual_type == expected_type else 'âŒ'}")
        
        # ğŸ†• ì‚¬ìš©ì ì¹œí™”ì  ë‹µë³€ ë¨¼ì € ì¶œë ¥
        print(f"\n{'='*80}")
        print("ğŸ’¬ [ì‚¬ìš©ììš© ë‹µë³€]")
        print("="*80)
        if "user_friendly_answer" in answer:
            print(answer["user_friendly_answer"])
        else:
            print("(ì‚¬ìš©ì ë‹µë³€ ì—†ìŒ)")
        
        # ğŸ†• êµ¬ì¡°í™”ëœ JSON ë‹µë³€ ì¶œë ¥ (ê°œë°œììš©)
        print(f"\n{'='*80}")
        print("ğŸ“Š [ê°œë°œììš© JSON ë‹µë³€]")
        print("="*80)
        # _metaì™€ user_friendly_answer ì œì™¸í•œ í•µì‹¬ ë‹µë³€ë§Œ
        json_answer = {k: v for k, v in answer.items() 
                      if k not in ["_meta", "user_friendly_answer"]}
        print(json.dumps(json_answer, ensure_ascii=False, indent=2))
        
        # ì°¸ì¡° ë¬¸ì„œ
        print(f"\n{'='*80}")
        print("ğŸ“š [ì°¸ì¡° ë¬¸ì„œ]")
        print("="*80)
        for i, s in enumerate(meta.get("sources", [])[:3], 1):
            score = s.get('relevance_score', 0)
            print(f"  [{i}] {s['doc_name']} (p.{s['page']}) - ê´€ë ¨ë„: {score:.3f}")


def main():
    print("="*80)
    print("ğŸ§ª ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    load_dotenv()
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    
    if not OPENAI_API_KEY:
        print("âŒ OPENAI_API_KEY í•„ìš”")
        return
    
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    
    vector_store_dir = os.path.join(project_root, "data", "vector_store", "construction_law")
    cache_dir = os.path.join(project_root, "data", "cache")
    
    print("\nğŸ”§ ì´ˆê¸°í™”...")
    
    em = EmbeddingManager(OPENAI_API_KEY, "construction_law", cache_dir=cache_dir)
    index = em.load_index(os.path.join(vector_store_dir, "faiss_index.bin"))
    metadata = em.load_metadata(os.path.join(vector_store_dir, "metadata.json"))
    
    if not index or not metadata:
        print("âŒ ì¸ë±ìŠ¤ ì—†ìŒ")
        return
    
    engine = LegalSearchEngine(index, metadata, em)
    classifier = QueryClassifier(OPENAI_API_KEY)
    qa_system = EnhancedLegalQASystem(engine, OPENAI_API_KEY)
    
    print("âœ… ì™„ë£Œ\n")
    
    try:
        test_classification(classifier)
        input("\nâ¸ï¸  Enter â†’ ë‹¤ìŒ ë‹¨ê³„...")
        
        test_search(engine, classifier)
        input("\nâ¸ï¸  Enter â†’ ë‹¤ìŒ ë‹¨ê³„...")
        
        test_full_qa(qa_system)
        
        print("\n" + "="*80)
        print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("="*80)
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()