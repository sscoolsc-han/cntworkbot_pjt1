"""
app.py
ê±´ì„¤ë²•ë ¹ ì±—ë´‡ Streamlit
- ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ í‘œì‹œ
- ì›ë³¸ JSON ë°ì´í„° ë³´ê´€
"""

import streamlit as st
import os
from dotenv import load_dotenv
from s4_EmbeddingManager import EmbeddingManager
from s5_LegalSearchEngine import LegalSearchEngine
from s62_GPTLegalSearchSystem import EnhancedLegalQASystem
from s61_QueryClassifier import QueryClassifier
import json
from io import BytesIO
from datetime import datetime

# PDF ìƒì„±ìš©
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.units import mm

load_dotenv()

st.set_page_config(
    page_title="ê±´ì„¤ë²•ë ¹ ì±—ë´‡",
    page_icon="ğŸ—ï¸",
    layout="wide"
)

# ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-title {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .query-badge {
        display: inline-block;
        padding: 0.3rem 0.8rem;
        border-radius: 15px;
        font-size: 0.9rem;
        font-weight: bold;
        background-color: #4ecdc4;
        color: white;
    }
</style>
""", unsafe_allow_html=True)


def create_pdf(title: str, content: str) -> BytesIO:
    """í…ìŠ¤íŠ¸ë¥¼ PDFë¡œ ë³€í™˜"""
    buffer = BytesIO()
    c = canvas.Canvas(buffer, pagesize=A4)
    width, height = A4
    
    font_paths = [
        "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
        "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
        "/System/Library/Fonts/AppleGothic.ttf",
        "C:/Windows/Fonts/malgun.ttf",
        "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"
    ]
    
    font_registered = False
    for font_path in font_paths:
        if os.path.exists(font_path):
            try:
                pdfmetrics.registerFont(TTFont('Korean', font_path))
                font_registered = True
                break
            except:
                continue
    
    font_name = 'Korean' if font_registered else 'Helvetica'
    
    c.setFont(font_name, 16)
    c.drawString(30*mm, height - 30*mm, title)
    
    c.setFont(font_name, 10)
    c.drawString(30*mm, height - 40*mm, f"ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    
    c.line(30*mm, height - 45*mm, width - 30*mm, height - 45*mm)
    
    c.setFont(font_name, 11)
    y_position = height - 55*mm
    line_height = 6*mm
    
    lines = content.split('\n')
    for line in lines:
        if y_position < 30*mm:
            c.showPage()
            c.setFont(font_name, 11)
            y_position = height - 30*mm
        
        while len(line) > 70:
            c.drawString(30*mm, y_position, line[:70])
            line = line[70:]
            y_position -= line_height
            if y_position < 30*mm:
                c.showPage()
                c.setFont(font_name, 11)
                y_position = height - 30*mm
        
        c.drawString(30*mm, y_position, line)
        y_position -= line_height
    
    c.save()
    buffer.seek(0)
    return buffer


def format_document_content(answer: dict) -> str:
    """ë¬¸ì„œ_ìƒì„± ì‘ë‹µì„ í¸ì§‘ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    doc_type = answer.get("ë¬¸ì„œ_ìœ í˜•", "ë¬¸ì„œ")
    title = answer.get("ì œëª©", "ì œëª© ì—†ìŒ")
    
    content_lines = [
        f"{'='*60}",
        f"{title}",
        f"{'='*60}",
        "",
        f"ë¬¸ì„œ ìœ í˜•: {doc_type}",
        f"ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d')}",
        "",
    ]
    
    if answer.get("ê·¼ê±°_ë²•ë ¹"):
        content_lines.append("[ ê·¼ê±° ë²•ë ¹ ]")
        for law in answer["ê·¼ê±°_ë²•ë ¹"]:
            content_lines.append(f"  â€¢ {law}")
        content_lines.append("")
    
    if answer.get("ë‚´ìš©"):
        content_lines.append("[ ì ê²€ í•­ëª© ]")
        content_lines.append("")
        for item in answer["ë‚´ìš©"]:
            ë²ˆí˜¸ = item.get("ë²ˆí˜¸", "-")
            í•­ëª© = item.get("í•­ëª©", "")
            ê¸°ì¤€ = item.get("ê¸°ì¤€", "")
            ë²•ì _ê·¼ê±° = item.get("ë²•ì _ê·¼ê±°", "")
            
            content_lines.append(f"{ë²ˆí˜¸}. {í•­ëª©}")
            content_lines.append(f"   ê¸°ì¤€: {ê¸°ì¤€}")
            if ë²•ì _ê·¼ê±°:
                content_lines.append(f"   ë²•ì  ê·¼ê±°: {ë²•ì _ê·¼ê±°}")
            content_lines.append(f"   ì ê²€ ê²°ê³¼: [ ] ì í•©  [ ] ë¶€ì í•©  [ ] í•´ë‹¹ì—†ìŒ")
            content_lines.append("")
    
    if answer.get("ì‚¬ìš©_ë°©ë²•"):
        content_lines.append("[ ì‚¬ìš© ë°©ë²• ]")
        content_lines.append(answer["ì‚¬ìš©_ë°©ë²•"])
        content_lines.append("")
    
    content_lines.extend([
        "",
        "â”€" * 60,
        "",
        "ì ê²€ì¼: ______ë…„ ____ì›” ____ì¼",
        "",
        "ì ê²€ì: _________________ (ì„œëª…)",
        "",
        "ê´€ë¦¬ê°ë…ì: _________________ (ì„œëª…)",
        "",
        "â”€" * 60,
    ])
    
    return "\n".join(content_lines)


@st.cache_resource
def load_system():
    """ì‹œìŠ¤í…œ ë¡œë“œ"""
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    
    if not OPENAI_API_KEY:
        st.error("âš ï¸ OPENAI_API_KEY í•„ìš”")
        st.stop()
    
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    
    vector_store_dir = os.path.join(project_root, "data", "vector_store", "construction_law")
    cache_dir = os.path.join(project_root, "data", "cache")
    
    with st.spinner("ğŸ”§ ì‹œìŠ¤í…œ ë¡œë”©..."):
        em = EmbeddingManager(OPENAI_API_KEY, "construction_law", cache_dir=cache_dir)
        
        index = em.load_index(os.path.join(vector_store_dir, "faiss_index.bin"))
        metadata = em.load_metadata(os.path.join(vector_store_dir, "metadata.json"))
        
        if not index or not metadata:
            st.error("âš ï¸ ì¸ë±ìŠ¤ íŒŒì¼ ì—†ìŒ")
            st.stop()
        
        engine = LegalSearchEngine(index, metadata, em)
        classifier = QueryClassifier(OPENAI_API_KEY)
        qa_system = EnhancedLegalQASystem(engine, OPENAI_API_KEY)
    
    return engine, classifier, qa_system


# ë©”ì¸
st.markdown('<p class="main-title">ğŸ—ï¸ ê±´ì„¤ë²•ë ¹ AI ì±—ë´‡</p>', unsafe_allow_html=True)

engine, classifier, qa_system = load_system()

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“– ì‚¬ìš© ê°€ì´ë“œ")
    st.markdown("""
    **ì§ˆë¬¸ ìœ í˜•:**
    - ğŸ”´ ë²•ì¡°ë¬¸: "ì œ36ì¡° ë‚´ìš©"
    - ğŸŸ¢ ì •ë³´: "ë¹„ê³„ ì•ˆì „ ê¸°ì¤€"
    - ğŸ”µ ì»¨ì„¤íŒ…: "3m ë¹„ê³„ ê´œì°®ì•„?"
    - ğŸŸ¡ ì ˆì°¨: "ìš©ë„ë³€ê²½ ì ˆì°¨"
    - ğŸŸ  ë¬¸ì„œ: "ì²´í¬ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ì–´"
    - ğŸŸ£ ë¹„êµ: "Aë²•ê³¼ Bë²• ì°¨ì´"
    """)
    
    st.markdown("---")
    
    st.header("ğŸ“ ë¬¸ì„œ ìƒì„± ê°€ì´ë“œ")
    st.markdown("""
    **ìš”ì²­ ì˜ˆì‹œ:**
    - "ë¹„ê³„ ì ê²€ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ì–´ì¤˜"
    - "ì•ˆì „ê´€ë¦¬ ê³„íšì„œ ì´ˆì•ˆ ì‘ì„±í•´ì¤˜"
    - "êµ´ì°©ì‘ì—… ì•ˆì „ì ê²€í‘œ ì–‘ì‹"
    
    **ìƒì„± í›„:**
    1. ğŸ“ í¸ì§‘ê¸°ì—ì„œ ìˆ˜ì •
    2. ğŸ’¾ TXT / ğŸ“„ PDF ë‹¤ìš´ë¡œë“œ
    """)
    
    st.markdown("---")
    
    # ìƒì„¸ ì •ë³´ í† ê¸€
    show_details = st.checkbox("ğŸ” ìƒì„¸ ì •ë³´ í‘œì‹œ", value=False)
    
    st.markdown("---")
    st.caption("ğŸ’¡ ë¬¸ì„œëŠ” ë²•ë ¹ ê¸°ë°˜ì´ì§€ë§Œ, ì „ë¬¸ê°€ ê²€í† ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []

if "current_document" not in st.session_state:
    st.session_state.current_document = None

if "document_title" not in st.session_state:
    st.session_state.document_title = ""

# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        
        # assistant ë©”ì‹œì§€ì´ê³  full_answerê°€ ìˆì„ ë•Œ
        if msg["role"] == "assistant" and "full_answer" in msg:
            full_answer = msg["full_answer"]
            meta = full_answer.get("_meta", {})
            search_results = meta.get("search_results", [])
            
            # ì¶œì²˜ê°€ ìˆì„ ë•Œë§Œ expander í‘œì‹œ
            if search_results:
                # show_detailsì— ë”°ë¼ expanded ì—¬ë¶€ ê²°ì •
                with st.expander("ğŸ“š ê·¼ê±° ë° ì¶œì²˜ ë³´ê¸°", expanded=show_details):
                    
                    # ê¸°ë³¸ ì •ë³´
                    query_type = meta.get("query_type", "N/A")
                    confidence = meta.get("classification", {}).get("confidence", 0)
                    
                    st.info(f"ğŸ·ï¸ **ì§ˆë¬¸ ìœ í˜•:** {query_type} | **í™•ì‹ ë„:** {confidence:.0%}")
                    
                    st.markdown("---")
                    st.markdown(f"##### ğŸ” ê²€ìƒ‰ëœ ì²­í¬ ({len(search_results)}ê°œ)")
                    
                    # ê° ì²­í¬ í‘œì‹œ
                    for i, result in enumerate(search_results, 1):
                        chunk_content = result.get('content', '')
                        metadata = result.get('metadata', {})
                        doc_name = metadata.get('doc_name', 'ë¬¸ì„œëª… ì—†ìŒ')
                        page = metadata.get('page', '?')
                        
                        # ê´€ë ¨ì„± ì ìˆ˜
                        relevance = result.get('rrf_score', result.get('score', 0))
                        
                        # ì²­í¬ ì •ë³´ í—¤ë”
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            st.markdown(f"**[ì²­í¬ {i}] {doc_name}** (í˜ì´ì§€ {page})")
                        with col2:
                            st.caption(f"ê´€ë ¨ì„±: {relevance:.3f}")
                        
                        # ì²­í¬ ë‚´ìš© í‘œì‹œ
                        st.text_area(
                            label=f"ì²­í¬ ë‚´ìš©",
                            value=chunk_content,
                            height=200,
                            key=f"chunk_{id(msg)}_{i}",
                            disabled=True,
                            label_visibility="collapsed"
                        )                       
                       
                        if i < len(search_results):
                            st.markdown("---")
# ë¬¸ì„œ í¸ì§‘ê¸° í‘œì‹œ
if st.session_state.current_document:
    st.markdown("---")
    st.markdown("### ğŸ“ ë¬¸ì„œ í¸ì§‘ê¸°")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        edited_content = st.text_area(
            "ë¬¸ì„œ ë‚´ìš© (ììœ ë¡­ê²Œ í¸ì§‘í•˜ì„¸ìš”)",
            value=st.session_state.current_document,
            height=400,
            key="document_editor"
        )
    
    with col2:
        st.markdown("**ğŸ“¥ ë‹¤ìš´ë¡œë“œ**")
        
        st.download_button(
            label="ğŸ’¾ TXT ì €ì¥",
            data=edited_content.encode('utf-8'),
            file_name=f"{st.session_state.document_title}.txt",
            mime="text/plain",
            use_container_width=True
        )
        
        try:
            pdf_buffer = create_pdf(st.session_state.document_title, edited_content)
            st.download_button(
                label="ğŸ“„ PDF ì €ì¥",
                data=pdf_buffer,
                file_name=f"{st.session_state.document_title}.pdf",
                mime="application/pdf",
                use_container_width=True
            )
        except Exception as e:
            st.warning(f"PDF ìƒì„± ì‹¤íŒ¨: {e}")
        
        st.markdown("---")
        
        if st.button("âŒ í¸ì§‘ê¸° ë‹«ê¸°", use_container_width=True):
            st.session_state.current_document = None
            st.session_state.document_title = ""
            st.rerun()

# ì±„íŒ… ì…ë ¥
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        
        # ===== ì§„í–‰ ìƒí™© í‘œì‹œ =====
        with st.status("ğŸ¤” ë‹µë³€ ìƒì„± ì¤‘...", expanded=True) as status:
            
            # 1ë‹¨ê³„: ì§ˆë¬¸ ë¶„ë¥˜
            st.write("ğŸ·ï¸ ì§ˆë¬¸ ìœ í˜• ë¶„ì„ ì¤‘...")
            classification = classifier.classify(prompt)
            query_type = classification["query_type"]
            confidence = classification["confidence"]
            st.write(f"   âœ… **{query_type}** (í™•ì‹ ë„: {confidence:.0%})")
            
            # 2ë‹¨ê³„: ê²€ìƒ‰ ì „ëµ
            st.write("ğŸ” ê²€ìƒ‰ ì „ëµ ê²°ì • ì¤‘...")
            strategy = classifier.get_search_strategy(query_type)
            st.write(f"   âœ… {strategy['search_method']} ê²€ìƒ‰ (top_k={strategy['top_k']})")
            
            # 3ë‹¨ê³„: ë¬¸ì„œ ê²€ìƒ‰
            st.write("ğŸ“š ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘...")
            search_results = engine.hybrid_search(prompt, top_k=strategy['top_k'])
            st.write(f"   âœ… {len(search_results)}ê°œ ë¬¸ì„œ ë°œê²¬")
            
            # 4ë‹¨ê³„: ë‹µë³€ ìƒì„±
            st.write("âœï¸ GPT ë‹µë³€ ìƒì„± ì¤‘...")
            answer = qa_system.generate_answer(prompt, verbose=False, format_for_user=True)
            st.write("   âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ!")
            
            status.update(label="âœ… ë‹µë³€ ì™„ë£Œ!", state="complete", expanded=False)
        
        # ===== ë‹µë³€ í‘œì‹œ =====
        meta = answer.get("_meta", {})
        query_type = meta.get("query_type", "ì¼ë°˜_ì •ë³´_ê²€ìƒ‰")
        confidence = meta.get("classification", {}).get("confidence", 0)
        
        # ìœ í˜• ë°°ì§€
        st.markdown(f"""
        <span class="query-badge">{query_type}</span>
        <span style="color: gray;"> (í™•ì‹ ë„: {confidence:.0%})</span>
        """, unsafe_allow_html=True)
        
        st.markdown("---")
        
        # ===== ë¬¸ì„œ_ìƒì„±ë§Œ íŠ¹ë³„ ì²˜ë¦¬ =====
        if query_type == "ë¬¸ì„œ_ìƒì„±":
            ì œëª© = answer.get("ì œëª©", "ìƒì„±ëœ ë¬¸ì„œ")
            
            st.success(f"ğŸ“„ **{ì œëª©}** ë¬¸ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            document_content = format_document_content(answer)
            
            st.session_state.current_document = document_content
            st.session_state.document_title = ì œëª©
            
            st.markdown("**ğŸ“‹ ë¬¸ì„œ ë¯¸ë¦¬ë³´ê¸°:**")
            st.code(document_content[:500] + "..." if len(document_content) > 500 else document_content)
            
            st.info("ğŸ‘† ìœ„ 'ë¬¸ì„œ í¸ì§‘ê¸°'ì—ì„œ ë‚´ìš©ì„ ìˆ˜ì •í•˜ê³  ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            display_text = f"ğŸ“„ {ì œëª©} ë¬¸ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ í¸ì§‘ê¸°ì—ì„œ ìˆ˜ì • í›„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”."
            st.session_state.messages.append({
                "role": "assistant", 
                "content": display_text,
                "full_answer": answer  # ì›ë³¸ ë³´ê´€
            })
            
            st.rerun()
        
        # ===== ë‚˜ë¨¸ì§€: user_friendly_answer í‘œì‹œ =====
        else:
            display_text = answer.get("user_friendly_answer", "ë‹µë³€ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
            st.markdown(display_text)
            
            st.session_state.messages.append({
                "role": "assistant", 
                "content": display_text,
                "full_answer": answer  # ì›ë³¸ ë³´ê´€
            })