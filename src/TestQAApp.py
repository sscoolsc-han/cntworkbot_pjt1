"""
app.py
ê±´ì„¤ë²•ë ¹ ì±—ë´‡ Streamlit
- ì§„í–‰ ìƒí™© ì‹¤ì‹œê°„ í‘œì‹œ
- ì›ë³¸ JSON ë°ì´í„° ë³´ê´€
"""

import streamlit as st
import os
from dotenv import load_dotenv
from s4_EmbeddingManager import EmbeddingManager
from s5_LegalSearchEngine import LegalSearchEngine
from s62_GPTLegalSearchSystem import EnhancedLegalQASystem
from s61_QueryClassifier import QueryClassifier
from io import BytesIO
from datetime import datetime
import time

# PDF ìƒì„±ìš©
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.units import mm

load_dotenv()

st.set_page_config(
    page_title="ê±´ì„¤ë²•ë ¹ ì±—ë´‡",
    page_icon="ğŸ—ï¸",
    layout="wide"
)

if "messages" not in st.session_state:
    st.session_state.messages = []

if "current_document" not in st.session_state:
    st.session_state.current_document = None

if "document_title" not in st.session_state:
    st.session_state.document_title = ""

# ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-title {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .query-badge {
        display: inline-block;
        padding: 0.3rem 0.8rem;
        border-radius: 15px;
        font-size: 0.9rem;
        font-weight: bold;
        background-color: #4ecdc4;
        color: white;
    }
</style>
""", unsafe_allow_html=True)


def create_pdf(title: str, content: str) -> BytesIO:
    """í…ìŠ¤íŠ¸ë¥¼ PDFë¡œ ë³€í™˜"""
    buffer = BytesIO()
    c = canvas.Canvas(buffer, pagesize=A4)
    width, height = A4
    
    font_paths = [
        "/usr/share/fonts/truetype/nanum/NanumGothic.ttf",
        "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
        "/System/Library/Fonts/AppleGothic.ttf",
        "C:/Windows/Fonts/malgun.ttf",
        "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"
    ]
    
    font_registered = False
    for font_path in font_paths:
        if os.path.exists(font_path):
            try:
                pdfmetrics.registerFont(TTFont('Korean', font_path))
                font_registered = True
                break
            except:
                continue
    
    font_name = 'Korean' if font_registered else 'Helvetica'
    
    c.setFont(font_name, 16)
    c.drawString(30*mm, height - 30*mm, title)
    
    c.setFont(font_name, 10)
    c.drawString(30*mm, height - 40*mm, f"ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    
    c.line(30*mm, height - 45*mm, width - 30*mm, height - 45*mm)
    
    c.setFont(font_name, 11)
    y_position = height - 55*mm
    line_height = 6*mm
    
    lines = content.split('\n')
    for line in lines:
        if y_position < 30*mm:
            c.showPage()
            c.setFont(font_name, 11)
            y_position = height - 30*mm
        
        while len(line) > 70:
            c.drawString(30*mm, y_position, line[:70])
            line = line[70:]
            y_position -= line_height
            if y_position < 30*mm:
                c.showPage()
                c.setFont(font_name, 11)
                y_position = height - 30*mm
        
        c.drawString(30*mm, y_position, line)
        y_position -= line_height
    
    c.save()
    buffer.seek(0)
    return buffer


def format_document_content(answer: dict) -> str:
    """ë¬¸ì„œ_ìƒì„± ì‘ë‹µì„ í¸ì§‘ ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    doc_type = answer.get("ë¬¸ì„œ_ìœ í˜•", "ë¬¸ì„œ")
    title = answer.get("ì œëª©", "ì œëª© ì—†ìŒ")
    
    content_lines = [
        f"{'='*60}",
        f"{title}",
        f"{'='*60}",
        "",
        f"ë¬¸ì„œ ìœ í˜•: {doc_type}",
        f"ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d')}",
        "",
    ]
    
    if answer.get("ê·¼ê±°_ë²•ë ¹"):
        content_lines.append("[ ê·¼ê±° ë²•ë ¹ ]")
        for law in answer["ê·¼ê±°_ë²•ë ¹"]:
            content_lines.append(f"  â€¢ {law}")
        content_lines.append("")
    
    if answer.get("ë‚´ìš©"):
        content_lines.append("[ ì ê²€ í•­ëª© ]")
        content_lines.append("")
        for item in answer["ë‚´ìš©"]:
            ë²ˆí˜¸ = item.get("ë²ˆí˜¸", "-")
            í•­ëª© = item.get("í•­ëª©", "")
            ê¸°ì¤€ = item.get("ê¸°ì¤€", "")
            ë²•ì _ê·¼ê±° = item.get("ë²•ì _ê·¼ê±°", "")
            
            content_lines.append(f"{ë²ˆí˜¸}. {í•­ëª©}")
            content_lines.append(f"   ê¸°ì¤€: {ê¸°ì¤€}")
            if ë²•ì _ê·¼ê±°:
                content_lines.append(f"   ë²•ì  ê·¼ê±°: {ë²•ì _ê·¼ê±°}")
            content_lines.append(f"   ì ê²€ ê²°ê³¼: [ ] ì í•©  [ ] ë¶€ì í•©  [ ] í•´ë‹¹ì—†ìŒ")
            content_lines.append("")
    
    if answer.get("ì‚¬ìš©_ë°©ë²•"):
        content_lines.append("[ ì‚¬ìš© ë°©ë²• ]")
        content_lines.append(answer["ì‚¬ìš©_ë°©ë²•"])
        content_lines.append("")
    
    content_lines.extend([
        "",
        "â”€" * 60,
        "",
        "ì ê²€ì¼: ______ë…„ ____ì›” ____ì¼",
        "",
        "ì ê²€ì: _________________ (ì„œëª…)",
        "",
        "ê´€ë¦¬ê°ë…ì: _________________ (ì„œëª…)",
        "",
        "â”€" * 60,
    ])
    
    return "\n".join(content_lines)


def show_sources_expander(answer, unique_key=None):
    """
    ê·¼ê±° ë° ì¶œì²˜ë¥¼ expanderë¡œ í‘œì‹œí•˜ëŠ” ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜
    
    Args:
        answer: GPT ì‘ë‹µ ì „ì²´ (ë©”íƒ€ë°ì´í„° í¬í•¨)
        unique_key: Streamlit ìœ„ì ¯ í‚¤ ì¤‘ë³µ ë°©ì§€ìš© ê³ ìœ  ë¬¸ìì—´
    """
    if unique_key is None:
        unique_key = f"msg_{len(st.session_state.messages)}_{int(time.time())}"

    # 1. ë©”íƒ€ë°ì´í„°ì—ì„œ ê²€ìƒ‰ ê²°ê³¼ ì¶”ì¶œ
    meta = answer.get("_meta", {})
    search_results = meta.get("search_results", [])
    
    # 2. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì•„ë¬´ê²ƒë„ í‘œì‹œí•˜ì§€ ì•ŠìŒ
    if not search_results:
        return
    
    # 3. ì ‘ì—ˆë‹¤ í¼ ìˆ˜ ìˆëŠ” expander ìƒì„±
    with st.expander("ğŸ“š ê·¼ê±° ë° ì¶œì²˜ ë³´ê¸°"):        
        st.markdown("---")
        st.markdown(f"##### ğŸ” ê²€ìƒ‰ëœ ì²­í¬ ({len(search_results)}ê°œ)")
        
        # 4. ê° ê²€ìƒ‰ ê²°ê³¼(ì²­í¬)ë¥¼ ìˆœíšŒí•˜ë©° í‘œì‹œ
        for i, result in enumerate(search_results, 1):
            # ì²­í¬ ë°ì´í„° ì¶”ì¶œ
            chunk_content = result.get('content', '')
            metadata = result.get('metadata', {})
            doc_name = metadata.get('doc_name', 'ë¬¸ì„œëª… ì—†ìŒ')
            page = metadata.get('page', '?')
            
            # ì²­í¬ í—¤ë” í‘œì‹œ
            st.markdown(f"**[ì²­í¬ {i}] {doc_name}** (í˜ì´ì§€ {page})")
            
            # ì²­í¬ ë‚´ìš©ì„ ì½ê¸° ì „ìš© í…ìŠ¤íŠ¸ ë°•ìŠ¤ë¡œ í‘œì‹œ
            st.text_area(
                label=f"ì²­í¬ ë‚´ìš©",
                value=chunk_content,
                height=200,
                key=f"chunk_{unique_key}_{i}",  # ê³ ìœ  í‚¤ë¡œ ì¶©ëŒ ë°©ì§€
                disabled=True,                   # ì½ê¸° ì „ìš©
                label_visibility="collapsed"     # ë¼ë²¨ ìˆ¨ê¹€
            )
            
            # ë§ˆì§€ë§‰ ì²­í¬ê°€ ì•„ë‹ˆë©´ êµ¬ë¶„ì„  í‘œì‹œ
            if i < len(search_results):
                st.markdown("---")


@st.cache_resource
def load_system():
    """ì‹œìŠ¤í…œ ë¡œë“œ"""
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    
    if not OPENAI_API_KEY:
        st.error("âš ï¸ OPENAI_API_KEY í•„ìš”")
        st.stop()
    
    current_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(current_dir)
    
    vector_store_dir = os.path.join(project_root, "data", "vector_store", "construction_law")
    cache_dir = os.path.join(project_root, "data", "cache")
    
    with st.spinner("ğŸ”§ ì‹œìŠ¤í…œ ë¡œë”©..."):
        em = EmbeddingManager(OPENAI_API_KEY, "construction_law", cache_dir=cache_dir)
        
        index = em.load_index(os.path.join(vector_store_dir, "faiss_index.bin"))
        metadata = em.load_metadata(os.path.join(vector_store_dir, "metadata.json"))
        
        if not index or not metadata:
            st.error("âš ï¸ ì¸ë±ìŠ¤ íŒŒì¼ ì—†ìŒ")
            st.stop()
        
        engine = LegalSearchEngine(index, metadata, em)
        classifier = QueryClassifier(OPENAI_API_KEY)
        qa_system = EnhancedLegalQASystem(engine, OPENAI_API_KEY)
    
    return engine, classifier, qa_system


# ë©”ì¸
st.markdown('<p class="main-title">ğŸ—ï¸ ê±´ì„¤ë²•ë ¹ AI ì±—ë´‡</p>', unsafe_allow_html=True)

engine, classifier, qa_system = load_system()

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“– ì‚¬ìš© ê°€ì´ë“œ")
    st.markdown("""
    **ì§ˆë¬¸ ìœ í˜•:**
    - ğŸ”´ ë²•ì¡°ë¬¸: "ì œ36ì¡° ë‚´ìš©"
    - ğŸŸ¢ ì •ë³´: "ë¹„ê³„ ì•ˆì „ ê¸°ì¤€"
    - ğŸ”µ ì»¨ì„¤íŒ…: "3m ë¹„ê³„ ê´œì°®ì•„?"
    - ğŸŸ¡ ì ˆì°¨: "ìš©ë„ë³€ê²½ ì ˆì°¨"
    - ğŸŸ  ë¬¸ì„œ: "ì²´í¬ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ì–´"
    - ğŸŸ£ ë¹„êµ: "Aë²•ê³¼ Bë²• ì°¨ì´"
    """)
    
    st.markdown("---")
    
    st.header("ğŸ“ ë¬¸ì„œ ìƒì„± ê°€ì´ë“œ")
    st.markdown("""
    **ìš”ì²­ ì˜ˆì‹œ:**
    - "ë¹„ê³„ ì ê²€ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ì–´ì¤˜"
    - "ì•ˆì „ê´€ë¦¬ ê³„íšì„œ ì´ˆì•ˆ ì‘ì„±í•´ì¤˜"
    - "êµ´ì°©ì‘ì—… ì•ˆì „ì ê²€í‘œ ì–‘ì‹"
    
    **ìƒì„± í›„:**
    1. ğŸ“ í¸ì§‘ê¸°ì—ì„œ ìˆ˜ì •
    2. ğŸ’¾ TXT / ğŸ“„ PDF ë‹¤ìš´ë¡œë“œ
    """)
    
    st.markdown("---")
    
    st.caption("ğŸ’¡ ë¬¸ì„œëŠ” ë²•ë ¹ ê¸°ë°˜ì´ì§€ë§Œ, ì „ë¬¸ê°€ ê²€í† ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")

# ============================================================
# ğŸ“œ ì±„íŒ… ê¸°ë¡ í‘œì‹œ (í˜ì´ì§€ ë¡œë”© ì‹œ ì‹¤í–‰)
# ============================================================
for idx, msg in enumerate(st.session_state.messages):
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        
        # assistant ë©”ì‹œì§€ì´ê³  full_answerê°€ ìˆì„ ë•Œë§Œ ì¶œì²˜ í‘œì‹œ
        if msg["role"] == "assistant" and "full_answer" in msg:
            show_sources_expander(msg["full_answer"], unique_key=f"history_{idx}")

# ============================================================
# ğŸ“ ë¬¸ì„œ í¸ì§‘ê¸° í‘œì‹œ
# ============================================================
if st.session_state.current_document:
    st.markdown("---")
    st.markdown("### ğŸ“ ë¬¸ì„œ í¸ì§‘ê¸°")
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        edited_content = st.text_area(
            "ë¬¸ì„œ ë‚´ìš© (ììœ ë¡­ê²Œ í¸ì§‘í•˜ì„¸ìš”)",
            value=st.session_state.current_document,
            height=400,
            key="document_editor"
        )
    
    with col2:
        st.markdown("**ğŸ“¥ ë‹¤ìš´ë¡œë“œ**")
        
        st.download_button(
            label="ğŸ’¾ TXT ì €ì¥",
            data=edited_content.encode('utf-8'),
            file_name=f"{st.session_state.document_title}.txt",
            mime="text/plain",
            use_container_width=True
        )
        
        try:
            pdf_buffer = create_pdf(st.session_state.document_title, edited_content)
            st.download_button(
                label="ğŸ“„ PDF ì €ì¥",
                data=pdf_buffer,
                file_name=f"{st.session_state.document_title}.pdf",
                mime="application/pdf",
                use_container_width=True
            )
        except Exception as e:
            st.warning(f"PDF ìƒì„± ì‹¤íŒ¨: {e}")
        
        st.markdown("---")
        
        if st.button("âŒ í¸ì§‘ê¸° ë‹«ê¸°", use_container_width=True):
            st.session_state.current_document = None
            st.session_state.document_title = ""
            st.rerun()


# ============================================================
# ğŸ’¬ ìƒˆë¡œìš´ ì§ˆë¬¸ ì…ë ¥ ì²˜ë¦¬
# ============================================================
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    
    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì €ì¥í•˜ê³  í™”ë©´ì— í‘œì‹œ
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # AI ë‹µë³€ ìƒì„±
    # ===== 1ë‹¨ê³„: ì§„í–‰ ìƒí™© í‘œì‹œ =====
    with st.status("ğŸ¤” ë‹µë³€ ìƒì„± ì¤‘...", expanded=True) as status:
        
        def progress_cb(msg):
            st.write(msg)

        answer = qa_system.generate_answer(
            prompt, 
            format_for_user=True,
            progress_callback=progress_cb
        )

        status.update(label="âœ… ë‹µë³€ ì™„ë£Œ!", state="complete", expanded=False)
    
    # ===== 2ë‹¨ê³„: ë‹µë³€ íƒ€ì… í™•ì¸ =====
    meta = answer.get("_meta", {})
    query_type = meta.get("query_type", "ì¼ë°˜_ì •ë³´_ê²€ìƒ‰")
    
    st.markdown("---")
    
    # ===== 3ë‹¨ê³„: ë‹µë³€ íƒ€ì…ì— ë”°ë¼ ë¶„ê¸° ì²˜ë¦¬ =====
    
    # ğŸ“„ ë¬¸ì„œ ìƒì„± íƒ€ì…
    if query_type == "ë¬¸ì„œ_ìƒì„±":
        ì œëª© = answer.get("ì œëª©", "ìƒì„±ëœ ë¬¸ì„œ")
        
        # ì„±ê³µ ë©”ì‹œì§€ í‘œì‹œ
        st.success(f"ğŸ“„ **{ì œëª©}** ë¬¸ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        
        # ë¬¸ì„œ ë‚´ìš© í¬ë§·íŒ…
        document_content = format_document_content(answer)
        
        # ì„¸ì…˜ ìƒíƒœì— ë¬¸ì„œ ì €ì¥ (í¸ì§‘ê¸° í™œì„±í™”ìš©)
        st.session_state.current_document = format_document_content(answer)
        st.session_state.document_title = ì œëª©        
        # í™”ë©´ì— í‘œì‹œí•  ê°„ë‹¨í•œ í…ìŠ¤íŠ¸
        display_text = f"ğŸ“„ {ì œëª©} ë¬¸ì„œê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ í¸ì§‘ê¸°ì—ì„œ ìˆ˜ì • í›„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”."    

        # ì„¸ì…˜ì— ì €ì¥
        st.session_state.messages.append({
            "role": "assistant", 
            "content": display_text,
            "full_answer": answer
        })
        
        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
        st.rerun()
    else:
        display_text = answer.get("user_friendly_answer", "ë‹µë³€ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

        # ì„¸ì…˜ì— ì €ì¥ (ì „ì²´ ë‹µë³€ í¬í•¨)
        st.session_state.messages.append({
            "role": "assistant", 
            "content": display_text,
            "full_answer": answer  # ì›ë³¸ JSON ë³´ê´€
        })
        
        # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ (í¸ì§‘ê¸° í™œì„±í™”)
        st.rerun()